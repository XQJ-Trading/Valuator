import { ref } from 'vue'
import type { Message } from '../types/Message'

export function useChat() {
  const query = ref('')
  const rule = ref('')
  const status = ref('ì¤€ë¹„ì™„ë£Œ')
  const loading = ref(false)
  const messages = ref<Message[]>([])
  const selectedModel = ref<string>('')
  const availableModels = ref<string[]>([])

  const API_BASE = import.meta.env.VITE_API_BASE || 'http://127.0.0.1:8000'

  // ì§€ì› ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
  async function fetchAvailableModels() {
    try {
      const res = await fetch(`${API_BASE}/api/v1/models`)
      const data = await res.json()
      availableModels.value = data.models || []
      if (!selectedModel.value && data.default) {
        selectedModel.value = data.default
      }
    } catch (error) {
      console.error('ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤:', error)
      // ê¸°ë³¸ê°’ ì„¤ì •
      availableModels.value = ['gemini-flash-latest', 'gemini-pro-latest']
      selectedModel.value = 'gemini-flash-latest'
    }
  }

  function clearAll() {
    messages.value = []
    query.value = ''
    rule.value = ''
    status.value = 'ì¤€ë¹„ì™„ë£Œ'
  }

  function setModel(model: string) {
    selectedModel.value = model
  }

  function buildQueryWithRule() {
    if (!rule.value.trim()) {
      return query.value
    }
    return `${query.value}\n<rule>\n${rule.value}\n</rule>`
  }

  function addMessage(type: Message['type'], content: string, metadata?: any) {
    messages.value.push({
      type,
      content,
      metadata,
      timestamp: new Date()
    })
  }

  async function send() {
    if (!query.value.trim()) return
    
    loading.value = true
    status.value = 'ì „ì†¡ì¤‘...'
    
    try {
      const queryWithRule = buildQueryWithRule()
      const requestBody = {
        query: queryWithRule,
        ...(selectedModel.value && { model: selectedModel.value })
      }
      
      const res = await fetch(`${API_BASE}/api/v1/chat`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(requestBody),
      })
      const json = await res.json()
      
      addMessage('final_answer', json.response || 'ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')
      status.value = 'ì™„ë£Œ'
      query.value = ''
      rule.value = ''
    } catch (e: any) {
      status.value = 'ì˜¤ë¥˜ ë°œìƒ'
      addMessage('error', `ì „ì†¡ ì˜¤ë¥˜: ${String(e)}`)
    } finally {
      loading.value = false
    }
  }

  async function stream() {
    if (!query.value.trim()) return
    
    loading.value = true
    status.value = 'ìŠ¤íŠ¸ë¦¬ë°ì¤‘...'
    let currentTokenMessage: Message | null = null
    
    try {
      const queryWithRule = buildQueryWithRule()
      const requestBody = {
        query: queryWithRule,
        ...(selectedModel.value && { model: selectedModel.value })
      }

      const response = await fetch(`${API_BASE}/api/v1/chat/stream`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(requestBody),
      })

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`)
      }

      const reader = response.body?.getReader()
      if (!reader) {
        throw new Error('ìŠ¤íŠ¸ë¦¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
      }

      const decoder = new TextDecoder()
      let buffer = ''

      while (true) {
        const { done, value } = await reader.read()
        
        if (done) break

        buffer += decoder.decode(value, { stream: true })
        const lines = buffer.split('\n')
        buffer = lines.pop() || ''

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const dataStr = line.slice(6)
            if (dataStr.trim() === '') continue

            try {
              const data = JSON.parse(dataStr)
              
              if (data.type === 'token') {
                if (currentTokenMessage) {
                  currentTokenMessage.content += data.content
                } else {
                  currentTokenMessage = {
                    type: 'token',
                    content: data.content,
                    timestamp: new Date()
                  }
                  messages.value.push(currentTokenMessage)
                }
              } else if (data.type === 'start') {
                currentTokenMessage = null
                addMessage('start', data.query || 'ì‹œì‘', {
                  query: data.query
                })
              } else if (data.type === 'end') {
                currentTokenMessage = null
                addMessage('end', 'ì™„ë£Œ', {})
              } else {
                currentTokenMessage = null
                addMessage(data.type, data.content || '', {
                  tool: data.tool,
                  tool_input: data.tool_input,
                  tool_output: data.tool_output,
                  error: data.error,
                  message: data.message,
                  tool_result: data.tool_result
                })
              }
              
              // ìƒíƒœ ì—…ë°ì´íŠ¸
              if (data.type === 'thought') {
                status.value = 'ğŸ§  ì‚¬ê³ ì¤‘...'
              } else if (data.type === 'action') {
                status.value = `âš¡ ${data.tool || 'ë„êµ¬'} ì‹¤í–‰ì¤‘...`
              } else if (data.type === 'observation') {
                status.value = 'ğŸ‘ï¸ ê²°ê³¼ ë¶„ì„ì¤‘...'
              }
            } catch (err) {
              console.warn('ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:', err, 'Data:', dataStr)
            }
          } else if (line.startsWith('event: end')) {
            status.value = 'ì™„ë£Œ'
            query.value = ''
            rule.value = ''
            loading.value = false
            break
          }
        }
      }
    } catch (e: any) {
      status.value = 'ì˜¤ë¥˜ ë°œìƒ'
      addMessage('error', `ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: ${String(e)}`)
      loading.value = false
    }
  }

  // ì»´í¬ë„ŒíŠ¸ê°€ ë§ˆìš´íŠ¸ë  ë•Œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜´
  fetchAvailableModels()

  return {
    query,
    rule,
    status,
    loading,
    messages,
    selectedModel,
    availableModels,
    clearAll,
    send,
    stream,
    setModel,
    fetchAvailableModels
  }
}
